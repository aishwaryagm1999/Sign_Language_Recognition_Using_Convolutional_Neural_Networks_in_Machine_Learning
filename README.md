ASLVizNet
Real-Time American Sign Language Recognition using CNN & TensorFlow Object Detection API
ğŸ“Œ Overview

ASLVizNet is a real-time computer vision framework designed for recognizing static American Sign Language (ASL) alphabets and numbers using deep convolutional neural networks and transfer learning.

The system leverages the TensorFlow Object Detection API and SSD MobileNet v2 to perform bounding box localization and classification of hand gestures from live webcam input.

ASLVizNet was developed as a research-driven project and presented at the IACIT 2021 Conference, with publication in IJARCS (International Journal of Advanced Research in Computer Science).

ğŸ¯ Problem Statement

Traditional sign language translation systems:

Depend on expensive sensor gloves

Require specialized hardware

Lack real-time responsiveness

Provide limited accessibility

ASLVizNet proposes a low-cost, vision-based deep learning approach that:

Uses only a webcam

Performs real-time detection

Achieves high accuracy (96â€“99%)

Requires no wearable devices

ğŸ—ï¸ System Architecture
Webcam Input (OpenCV)
        â†“
Image Annotation (LabelImg - XML)
        â†“
XML â†’ TFRecord Conversion
        â†“
TensorFlow Object Detection API
        â†“
SSD MobileNet v2 (Transfer Learning)
        â†“
Real-Time Detection with Bounding Box + Confidence Score
ğŸ§  Deep Learning Methodology
ğŸ”¹ Model Architecture

Model: SSD MobileNet v2

Framework: TensorFlow Object Detection API

Approach: Transfer Learning

Detection Type: Object Detection (Bounding Box + Classification)

ğŸ”¹ Why SSD MobileNet v2?

Lightweight architecture

Optimized for real-time inference

Efficient for low-compute environments

Strong balance between speed and accuracy

ğŸ“‚ Dataset Pipeline
1ï¸âƒ£ Data Collection

Custom ASL gesture dataset created

Static alphabets (Aâ€“Z)

Numbers (0â€“9)

Images captured using OpenCV

2ï¸âƒ£ Annotation

Tool: LabelImg

Generated XML annotation files

Bounding box coordinates labeled per image

3ï¸âƒ£ TFRecord Generation

Used custom script:

generate_tfrecord.py

This script:

Parses XML files

Converts annotations to TFRecord format

Maps labels using .pbtxt

Optionally generates CSV file

ğŸ”¬ Model Training
Training Configuration

Framework: TensorFlow

Training Steps: 10,000 epochs

Final Training Loss: 0.086

Hardware Used

Intel i5 Processor

8GB RAM

GTX 1030 (Optional GPU Acceleration)

Webcam for live testing

Training Process

Cloned TensorFlow Model Zoo

Selected SSD MobileNet v2 configuration

Modified pipeline.config

Generated label map (.pbtxt)

Converted dataset to TFRecord

Trained model

Exported trained model for inference

ğŸ“Š Experimental Results
Metric	Value
Training Epochs	10,000
Final Loss	0.086
Real-Time Accuracy	96% â€“ 99%
Detection Output	Bounding Box + Confidence Score
Input Device	Webcam

The system successfully performs real-time gesture detection with high confidence prediction scores.

ğŸ› ï¸ Technologies Used
ğŸ”¹ Programming

Python 3.x

ğŸ”¹ Computer Vision

OpenCV

NumPy

Pillow

ğŸ”¹ Deep Learning

TensorFlow

TensorFlow Object Detection API

SSD MobileNet v2

Transfer Learning

TFRecord format

Label Map (.pbtxt)

ğŸ”¹ Data Processing

Pandas

XML parsing (ElementTree)

TFRecord serialization

â–¶ï¸ Steps to Reproduce
1ï¸âƒ£ Clone Repository
git clone https://github.com/yourusername/ASLVizNet.git
cd ASLVizNet
2ï¸âƒ£ Install Dependencies
pip install tensorflow opencv-python pandas numpy pillow lxml

Install TensorFlow Object Detection API dependencies.

3ï¸âƒ£ Annotate Dataset

Capture gesture images

Annotate using LabelImg

Save XML files in /annotations

4ï¸âƒ£ Generate TFRecords
python generate_tfrecord.py \
-x annotations \
-l label_map.pbtxt \
-o train.record \
-i images
5ï¸âƒ£ Train Model
python model_main_tf2.py \
--pipeline_config_path=training/pipeline.config \
--model_dir=training/ \
--alsologtostderr
6ï¸âƒ£ Run Real-Time Detection
python real_time_detection.py

Webcam will activate and display:

Bounding box

Predicted ASL character

Confidence score

ğŸ“š Research Publication

Presented at:

IACIT 2021 Conference

Published in:

International Journal of Advanced Research in Computer Science (IJARCS)

â€œSign Language Recognition using Convolutional Neural Networks in Machine Learningâ€, IJARCS, Vol. 12, pp. 16â€“20, Aug. 2021.
DOI: 10.26483/ijarcs.v12i0.6713

ğŸ“ Skills Demonstrated

Computer Vision

Deep Learning

TensorFlow Ecosystem

Transfer Learning

Dataset Engineering

TFRecord Pipeline Development

Real-Time ML Deployment

Research Publication & Presentation
